import json
import os
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

def deep_merge(target: Dict[str, Any], source: Dict[str, Any]):
    """ê°„ë‹¨í•œ ë”•ì…”ë„ˆë¦¬ ë”¥ ë¨¸ì§€ (metadata ë“± ì²˜ë¦¬ìš©)"""
    for key, value in source.items():
        if key == 'metadata' and isinstance(value, dict) and key in target and isinstance(target[key], dict):
            target[key].update(value)
        else:
            target[key] = value
    return target

def consolidate_data():
    """
    êµ­ë‚´(data/), ìˆ˜ì…(data/raw_imported/), ë³´ì™„(data/enriched/) ë°ì´í„°ë¥¼ ëª¨ë‘ ë³‘í•©í•©ë‹ˆë‹¤.
    ìš°ì„ ìˆœìœ„: Enriched > Raw Imported > Raw Local
    """
    RAW_DIR = Path('data')
    IMPORTED_DIR = Path('data/raw_imported')
    ENRICHED_DIR = Path('data/enriched')
    OUTPUT_FILE = Path('lib/db/ingested-data.json')
    
    consolidated_map = {}

    print("ğŸš€ ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„° í†µí•© ë° ê³ ë„í™” ì‹œì‘...")

    # 1. êµ­ë‚´ ë°ì´í„° ë¡œë“œ (Base)
    for file_path in RAW_DIR.glob('spirits_*.json'):
        if 'enriched' in file_path.name: continue # enriched í´ë”ì™€ í˜¼ë™ ë°©ì§€
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                items = json.load(f)
                for item in items:
                    ext_id = item.get('externalId')
                    if ext_id: consolidated_map[ext_id] = item
            print(f"  - [Raw Local] '{file_path.name}' ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"  - [Raw Local] '{file_path.name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    # 2. ìˆ˜ì… ë°ì´í„° ë¡œë“œ (Merge)
    for file_path in IMPORTED_DIR.glob('imported_*.json'):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                items = json.load(f)
                for item in items:
                    ext_id = item.get('externalId')
                    if not ext_id: continue
                    
                    if ext_id in consolidated_map:
                        deep_merge(consolidated_map[ext_id], item)
                    else:
                        consolidated_map[ext_id] = item
            print(f"  - [Raw Imported] '{file_path.name}' ë³‘í•© ì™„ë£Œ")
        except Exception as e:
            print(f"  - [Raw Imported] '{file_path.name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    # 3. ë³´ì™„ ë°ì´í„° ë¡œë“œ (High Priority Override)
    # whisky_enriched_batch_*.json íŒŒì¼ë“¤ì„ ë¡œë“œ
    for file_path in ENRICHED_DIR.glob('whisky_enriched_batch_*.json'):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                items = json.load(f)
                for item in items:
                    ext_id = item.get('externalId')
                    if not ext_id: continue
                    
                    if ext_id in consolidated_map:
                        # Enriched ë°ì´í„°ë¡œ ë®ì–´ì“°ê¸° (ë©”íƒ€ë°ì´í„° í¬í•¨)
                        deep_merge(consolidated_map[ext_id], item)
                    else:
                        consolidated_map[ext_id] = item
            print(f"  - [Enriched] '{file_path.name}' ìµœì¢… ë°˜ì˜ ì™„ë£Œ")
        except Exception as e:
            print(f"  - [Enriched] '{file_path.name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë³€í™˜ ë° í†µê³„
    final_list = list(consolidated_map.values())
    
    # lib/db í´ë” ìƒì„±
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_list, f, indent=2, ensure_ascii=False)

    print(f"\nâœ¨ ë°ì´í„° í†µí•© ì„œë²„(JSON) êµ¬ì¶• ì™„ë£Œ!")
    print(f"ì´ í†µí•© ë°ì´í„°: {len(final_list):,}ê±´")
    print(f"ğŸ’¾ ìµœì¢… DB ìœ„ì¹˜: {OUTPUT_FILE}")

if __name__ == "__main__":
    consolidate_data()
