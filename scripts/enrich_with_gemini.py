import os
import sys

# Force UTF-8 for Windows
sys.stdout.reconfigure(encoding='utf-8')
sys.stderr.reconfigure(encoding='utf-8')

import json
import time
import argparse
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any
from google import genai
from google.genai import types
# from dotenv import load_dotenv (Disabled: .env contains JS code causing parsing errors)

# Manual .env parser to support hybrid file format
def load_env_robust():
    env_vars = {}
    try:
        # Search for .env in current and parent directories
        current_dir = Path.cwd()
        potential_paths = [current_dir / '.env', current_dir.parent / '.env', Path(__file__).parent.parent / '.env']
        
        env_path = next((p for p in potential_paths if p.exists()), None)
        
        if env_path:
            with open(env_path, 'r', encoding='utf-8', errors='ignore') as f:
                for line in f:
                    line = line.strip()
                    # Skip JS objects or comments
                    if not line or line.startswith('#') or line.startswith('const ') or '{' in line or '}' in line:
                        continue
                    if '=' in line:
                        key, value = line.split('=', 1)
                        # Clean quotes
                        env_vars[key.strip()] = value.strip().strip("'").strip('"')
    except Exception as e:
        print(f"âš ï¸ Warning: Custom .env loading encountered error: {e}")
    return env_vars

# Load Config
env_conf = load_env_robust()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY") or env_conf.get("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    print("âŒ .env íŒŒì¼ì— GEMINI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    exit(1)

print(f"DEBUG: GEMINI_API_KEY Loaded: {'*' * 5}{GEMINI_API_KEY[-4:] if GEMINI_API_KEY else 'None'}")

# API í´ë¼ì´ì–¸íŠ¸ ë° ëª¨ë¸ ì„¤ì •
client = genai.Client(api_key=GEMINI_API_KEY)
MODEL_ID = "gemini-2.0-flash"

# 1. í‘œì¤€ ë©”íƒ€ë°ì´í„° ë¡œë“œ (ì¸ë±ìŠ¤ ì°¸ì¡°ìš©)
# ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
BASE_DIR = Path(__file__).parent.parent
METADATA_PATH = BASE_DIR / 'lib/constants/spirits-metadata.json'

with open(METADATA_PATH, 'r', encoding='utf-8') as f:
    METADATA = json.load(f)

def get_category_prompt(category: str) -> str:
    """ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    # ë©”íƒ€ë°ì´í„° í‚¤ ë§¤í•‘ (í•œê¸€ -> í‚¤)
    # ê°„ë‹¨í•˜ê²Œ êµ¬í˜„: whisky í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ whisky, ê·¸ ì™¸ì—ëŠ” ì¼ë°˜ ê°€ì´ë“œ
    cat_lower = str(category).lower()
    
    if 'whisky' in cat_lower or 'ìœ„ìŠ¤í‚¤' in cat_lower:
        categories = METADATA['categories'].get('ìœ„ìŠ¤í‚¤', {})
        return f"- ìœ„ìŠ¤í‚¤ ì¹´í…Œê³ ë¦¬ ê°€ì´ë“œ: {json.dumps(categories, ensure_ascii=False)}"
    elif 'gin' in cat_lower or 'ì§„' in cat_lower:
        return f"- ì§„(Gin) ì¹´í…Œê³ ë¦¬ ê°€ì´ë“œ: {json.dumps(METADATA['categories'].get('ì¼ë°˜ì¦ë¥˜ì£¼', {}).get('ì§„', []), ensure_ascii=False)}"
    elif 'rum' in cat_lower or 'ëŸ¼' in cat_lower:
        return f"- ëŸ¼(Rum) ì¹´í…Œê³ ë¦¬ ê°€ì´ë“œ: {json.dumps(METADATA['categories'].get('ì¼ë°˜ì¦ë¥˜ì£¼', {}).get('ëŸ¼', []), ensure_ascii=False)}"
    elif 'tequila' in cat_lower or 'í…Œí‚¬ë¼' in cat_lower or 'ë°í‚¬ë¼' in cat_lower:
        return f"- ë°í‚¬ë¼ ì¹´í…Œê³ ë¦¬ ê°€ì´ë“œ: {json.dumps(METADATA['categories'].get('ì¼ë°˜ì¦ë¥˜ì£¼', {}).get('ë°í‚¬ë¼/ë©”ì¦ˆì¹¼', []), ensure_ascii=False)}"
    elif 'brandy' in cat_lower or 'ë¸Œëœë””' in cat_lower or 'cognac' in cat_lower:
        return f"- ë¸Œëœë”” ì¹´í…Œê³ ë¦¬ ê°€ì´ë“œ: {json.dumps(METADATA['categories'].get('ë¸Œëœë””', []), ensure_ascii=False)}"
    else:
        # Default or Korean Spirits (ì†Œì£¼, íƒì£¼ ë“±)
        return f"- ì¼ë°˜/ê¸°íƒ€ ì£¼ë¥˜ ê°€ì´ë“œ: {json.dumps(METADATA['categories'].get('ì†Œì£¼', {}), ensure_ascii=False)}"

def enrich_batch(batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    # ì»¨í…ìŠ¤íŠ¸ ìµœì í™”: í•„ìš”í•œ ì •ë³´ë§Œ ì¶”ì¶œ
    minimal_batch = []
    
    # ë°°ì¹˜ ë‚´ì˜ ëŒ€í‘œ ì¹´í…Œê³ ë¦¬ íŒŒì•… (ì²« ë²ˆì§¸ ì•„ì´í…œ ê¸°ì¤€)
    primary_category = batch[0].get('category', 'unknown') if batch else 'unknown'
    category_guide = get_category_prompt(primary_category)
    
    tag_index = METADATA['tag_index']

    for item in batch:
        minimal_batch.append({
            "id": item['id'],
            "name_ko": item['name'],
            "name_en": item.get('metadata', {}).get('name_en', ''),
            "distillery": item['distillery'],
            "category": item.get('category', '')
        })

    prompt = f"""
ë„ˆëŠ” ì„¸ê³„ ìµœê³ ì˜ ë§ˆìŠ¤í„° ë¸”ë Œë”ì´ì ì£¼ë¥˜ ì „ë¬¸ ì†Œë¯ˆë¦¬ì—ì•¼. 
ì•„ë˜ ì£¼ë¥˜ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ ì „ë¬¸ì ì¸ í…Œì´ìŠ¤íŒ… ë°ì´í„°ì™€ ì •ë°€í•œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•´ì¤˜.

[ì¹´í…Œê³ ë¦¬ ê°€ì´ë“œ]
{category_guide}

[í…Œì´ìŠ¤íŒ… íƒœê·¸ ì¸ë±ìŠ¤ ê°€ì´ë“œ]
- ì•„ë˜ íƒœê·¸ë“¤ì„ ì°¸ê³ í•˜ì—¬ ê° í•­ëª©ë³„ë¡œ ì í•©í•œ í•´ì‹œíƒœê·¸ë¥¼ 3~5ê°œì”© ì„ íƒí•´.
- í–¥(Nose): {tag_index['nose']}
- ë§›/ì§ˆê°(Palate): {tag_index['palate']}
- ì—¬ìš´(Finish): {tag_index['finish']}

[ì‘ì„± ê·œì¹™]
1. abv: ì œí’ˆëª…ì— ì •ë³´ê°€ ì—†ë‹¤ë©´ í•´ë‹¹ ì œí’ˆì˜ ì¼ë°˜ì ì¸ ë„ìˆ˜ë¥¼ ì§€ì‹ìœ¼ë¡œ ì¶”ë¡ í•´(ì†Œì£¼: 16~20, ìœ„ìŠ¤í‚¤: 40~46 ë“±).
2. subcategory: ìœ„ ê°€ì´ë“œì˜ í‘œì¤€ ëª…ì¹­ì„ ì‚¬ìš©í•´.
3. Tags: ê° ì˜ì—­(nose, palate, finish)ì— ëŒ€í•´ ë°˜ë“œì‹œ ìœ„ ì¸ë±ìŠ¤ì˜ ë‹¨ì–´ë¥¼ í•´ì‹œíƒœê·¸(#) í˜•ì‹ìœ¼ë¡œ í¬í•¨í•´.
   - **ì¤‘ìš”**: ì¹´í…Œê³ ë¦¬ì— ì–½ë§¤ì´ì§€ ë§ê³  'ì œí’ˆëª…' ìì²´ë¥¼ ë¶„ì„í•˜ì—¬ ì›ì¬ë£Œë¥¼ ìœ ì¶”í•´.
   - ì˜ˆ: 'ë ¤(Ryeo)' -> ê³ êµ¬ë§ˆ ì¦ë¥˜ì†Œì£¼ (#ê³ êµ¬ë§ˆ, #ë¿Œë¦¬ì±„ì†Œ), 'ë¬¸ë°°ìˆ ' -> ë°°í–¥ (#ë°°, #ê³¡ë¬¼)
   - ì œí’ˆëª…ì— íŠ¹ì • ê³¼ì¼ì´ë‚˜ ì¬ë£Œ(ê³ êµ¬ë§ˆ, ê°ê·¤, í¬ë„ ë“±)ê°€ ë“¤ì–´ìˆë‹¤ë©´ ë°˜ë“œì‹œ í•´ë‹¹ ì¬ë£Œì˜ í’ë¯¸ë¥¼ íƒœê·¸ì— ë°˜ì˜í•´.

[CRITICAL ë°ì´í„° ì •ê·œí™” ê·œì¹™] â­ ë§¤ìš° ì¤‘ìš”!
4. country (ì œì¡°êµ­):
   - ë°˜ë“œì‹œ ê³µì‹ í•œê¸€ êµ­ê°€ëª…ì„ ì‚¬ìš©í•´: "ëŒ€í•œë¯¼êµ­", "ì˜êµ­", "ë¯¸êµ­", "í”„ë‘ìŠ¤", "ì¼ë³¸", "ìŠ¤í˜ì¸", "ì´íƒˆë¦¬ì•„"
   - ê¸ˆì§€ í‘œí˜„: "í•œêµ­", "Korea", "UK", "USA" ë“± ë¹„ê³µì‹ í‘œê¸°
   - ì˜ˆ: "í•œêµ­" â†’ "ëŒ€í•œë¯¼êµ­", "Korea" â†’ "ëŒ€í•œë¯¼êµ­", "UK" â†’ "ì˜êµ­"

5. region (ì§€ì—­):
   - ì ˆëŒ€ ì œì¡°êµ­ê³¼ ì¤‘ë³µë˜ì–´ì„œëŠ” ì•ˆ ë¨!
   - í•œêµ­: ì‹œÂ·ë„ ë‹¨ìœ„ ì‚¬ìš© ("ê²½ê¸°ë„", "ì œì£¼íŠ¹ë³„ìì¹˜ë„", "ì¶©ì²­ë‚¨ë„", "ì „ë¼ë¶ë„" ë“±)
     * ì‹œÂ·êµ° ë‹¨ìœ„ë„ í—ˆìš©: "ì•ˆë™ì‹œ", "ê²½ì£¼ì‹œ", "ë¶€ì•ˆêµ°"
     * ê¸ˆì§€: "ëŒ€í•œë¯¼êµ­", "í•œêµ­", "Korea" (ì œì¡°êµ­ê³¼ ì¤‘ë³µ)
   - ìŠ¤ì½”í‹€ëœë“œ ìœ„ìŠ¤í‚¤: "ìŠ¤í˜ì´ì‚¬ì´ë“œ", "ì•„ì¼ë¼", "í•˜ì´ëœë“œ", "ë¡œìš°ëœë“œ", "ìº ë²¨íƒ€ìš´", "ì•„ì¼ëœë“œ(Islands)"
     * ê¸ˆì§€: "ì˜êµ­", "ìŠ¤ì½”í‹€ëœë“œ" (ì œì¡°êµ­ê³¼ ì¤‘ë³µ)
   - ë¯¸êµ­: ì£¼(State) ë‹¨ìœ„ ("ì¼„í„°í‚¤", "í…Œë„¤ì‹œ", "ìº˜ë¦¬í¬ë‹ˆì•„", "ë‰´ìš•")
     * ê¸ˆì§€: "ë¯¸êµ­", "USA" (ì œì¡°êµ­ê³¼ ì¤‘ë³µ)
   - í”„ë‘ìŠ¤ ì™€ì¸: "ë¶€ë¥´ê³ ë‰´", "ë³´ë¥´ë„", "ìƒ´í˜ì¸", "ë¡ ", "ìƒ¤ë¸”ë¦¬"
     * ê¸ˆì§€: "í”„ë‘ìŠ¤" (ì œì¡°êµ­ê³¼ ì¤‘ë³µ)
   - ì§€ì—­ ì •ë³´ê°€ ì—†ê±°ë‚˜ ë¶ˆí™•ì‹¤í•˜ë©´ nullë¡œ ì„¤ì •í•´.

6. distillery_refined (ì¦ë¥˜ì†Œ/ì œì¡°ì‚¬):
   - ëª¨ë“  ë²•ì¸ í˜•íƒœ ì œê±°: "ì£¼ì‹íšŒì‚¬", "ãˆœ", "ë†ì—…íšŒì‚¬ë²•ì¸", "ìœ í•œíšŒì‚¬", "(ì£¼)", "CO., LTD.", "INC.", "LLC", "LIMITED" ë“±
   - ë¸Œëœë“œëª… ë˜ëŠ” ì¦ë¥˜ì†Œëª…ë§Œ ë‚¨ê²¨: "ãˆœí•œë¼ì‚°" â†’ "í•œë¼ì‚°", "ì£¼ì‹íšŒì‚¬ ê¸°ì› ìœ„ìŠ¤í‚¤ ì¦ë¥˜ì†Œ" â†’ "ê¸°ì› ìœ„ìŠ¤í‚¤ ì¦ë¥˜ì†Œ"
   - ìˆ˜ì¶œì…ì‚¬ ì˜ì‹¬ í‚¤ì›Œë“œ ì²´í¬: "ë¬´ì—­", "Trading", "Distribution", "Import", "Export", "International", "Global"
     * ì´ëŸ° í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì œì¡°ì‚¬ê°€ ì•„ë‹ ê°€ëŠ¥ì„±ì´ ë†’ìŒ. ì‹¤ì œ ì¦ë¥˜ì†Œëª…ì„ ì°¾ê±°ë‚˜ ì›ë˜ ì´ë¦„ ìœ ì§€.

7. abv (ë„ìˆ˜):
   - ë°˜ë“œì‹œ 0~100 ë²”ìœ„ì—¬ì•¼ í•¨. ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ nullë¡œ ì„¤ì •.
   - ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ í—ˆìš© (ì˜ˆ: 43.0, 17.5).

 ëŒ€ìƒ ëª©ë¡:
{json.dumps(minimal_batch, ensure_ascii=False)}

ë°˜ë“œì‹œ ì•„ë˜ êµ¬ì¡°ì˜ JSON ë°°ì—´ë¡œë§Œ ì‘ë‹µí•´ (Markdown ì½”ë“œ ë¸”ë¡ ì—†ì´):
[
  {{
    "id": "ì•„ì´í…œ ID",
    "abv": 40.0,
    "region": "ìƒì„¸ ì§€ì—­",
    "subcategory": "í‘œì¤€ ì¹´í…Œê³ ë¦¬ëª…",
    "distillery_refined": "ê³µì‹ ì œì¡°ì†Œ ëª…ì¹­",
    "nose_tags": ["#íƒœê·¸1"],
    "palate_tags": ["#íƒœê·¸2"],
    "finish_tags": ["#íƒœê·¸3"],
    "description_ko": "ì œí’ˆì˜ ì—­ì‚¬, íŠ¹ì§•, ë§›ì˜ ìƒì„¸í•œ ì„¤ëª… (í•œêµ­ì–´)",
    "description_en": "Detailed description in English",
    "pairing_guide_ko": "ì–´ìš¸ë¦¬ëŠ” ì•ˆì£¼ ë° í˜ì–´ë§ ê°€ì´ë“œ (í•œêµ­ì–´)",
    "pairing_guide_en": "Food pairing guide in English"
  }}
]
"""

    for attempt in range(3):
        try:
            response = client.models.generate_content(
                model=MODEL_ID,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            
            content = response.text.strip()
            # Markdown code block ì œê±°
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            content = content.strip()

            enriched_results = json.loads(content)
            
            mapping = {res['id']: res for res in enriched_results}
            for item in batch:
                res = mapping.get(item['id'])
                if res:
                    if res.get('abv'): item['abv'] = float(res['abv'])
                    if res.get('region'): item['region'] = res['region']
                    if res.get('subcategory'): item['subcategory'] = res['subcategory']
                    if res.get('distillery_refined'): item['distillery'] = res['distillery_refined']
                    if res.get('name_en'): item['name_en'] = res['name_en']
                    
                    # New Schema: Tags at ROOT
                    item['nose_tags'] = res.get('nose_tags', [])
                    item['palate_tags'] = res.get('palate_tags', [])
                    item['finish_tags'] = res.get('finish_tags', [])
                    
                    all_tags = (item.get('nose_tags') or []) + (item.get('palate_tags') or []) + (item.get('finish_tags') or [])
                    if all_tags:
                         item['tasting_note'] = ', '.join(all_tags)
                    
                    if 'metadata' not in item: item['metadata'] = {}
                    
                    # New Schema: Localized Descriptions/Pairings in METADATA
                    item['metadata']['description_ko'] = res.get('description_ko') or item['metadata'].get('description_ko')
                    item['metadata']['description_en'] = res.get('description_en') or item['metadata'].get('description_en')
                    item['metadata']['pairing_guide_ko'] = res.get('pairing_guide_ko') or item['metadata'].get('pairing_guide_ko')
                    item['metadata']['pairing_guide_en'] = res.get('pairing_guide_en') or item['metadata'].get('pairing_guide_en')
                    
                    item['isReviewed'] = True
                    item['status'] = 'ENRICHED' # ìƒíƒœ ì—…ë°ì´íŠ¸
                    item['updatedAt'] = datetime.now().isoformat()
            
            return batch

        except Exception as e:
            wait_time = (attempt + 1) * 2
            print(f"âš ï¸ Enrichment Attempt {attempt+1} Failed: {e}", flush=True)
            time.sleep(wait_time)
            
    print(f"âŒ Failed to enrich batch after 3 attempts.", flush=True)
    return batch

def main():
    parser = argparse.ArgumentParser(description='Enrich spirits data using Gemini AI')
    parser.add_argument('--input', required=True, help='Input JSON file path')
    parser.add_argument('--output', required=True, help='Output JSON file path')
    args = parser.parse_args()

    input_path = Path(args.input)
    output_path = Path(args.output)

    if not input_path.exists():
        print(f"Error: Not found {input_path}")
        return

    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Batch processing
        batch_size = 10
        enriched_data = []
        
        for i in range(0, len(data), batch_size):
            batch = data[i:i+batch_size]
            processed_batch = enrich_batch(batch)
            enriched_data.extend(processed_batch)
            time.sleep(1) # Rate limit

        # Ensure directory exists
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(enriched_data, f, indent=2, ensure_ascii=False)
            
        print(f"Success: Processed {len(enriched_data)} items")

        # Final Summary
        print("\n" + "="*50)
        print(" ğŸ“Š [SUMMARY] Gemini Enrichment")
        print("-" * 50)
        print(f"  â€¢ Input Items        : {len(data)}")
        print(f"  â€¢ Successfully Enriched : {len(enriched_data)}")
        print(f"  â€¢ Output File        : {output_path}")
        print("=" * 50 + "\n")

    except Exception as e:
        print(f"Error: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
