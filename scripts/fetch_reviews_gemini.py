import os
import json
import time
from pathlib import Path
from typing import List, Dict, Any
from google import genai
from google.genai import types
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not GEMINI_API_KEY:
    print("âŒ .env íŒŒì¼ì— GEMINI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    exit(1)

# Initialize Gemini Client
client = genai.Client(api_key=GEMINI_API_KEY)
MODEL_ID = "gemini-2.0-flash"

# File Paths
DATA_FILE = Path('lib/db/ingested-data.json')
BACKUP_FILE = Path('lib/db/ingested-data.backup.json')

def enrich_reviews_batch(batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    # Extract only ID and Name for the prompt to minimize tokens
    minimal_batch = []
    for item in batch:
        minimal_batch.append({
            "id": item['id'],
            "name": item['name']
        })

    prompt = f"""
    ë‹¹ì‹ ì€ ì£¼ë¥˜ ì „ë¬¸ ë¦¬ë·°ì–´ì´ì ì†Œë¯ˆë¦¬ì—ì…ë‹ˆë‹¤.
    ì•„ë˜ ì£¼ë¥˜ ëª©ë¡({len(minimal_batch)}ê°œ)ì— ëŒ€í•´, ê° ì œí’ˆì˜ 'ìµœì‹ /ëŒ€í‘œ ë¦¬ë·°'ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ì ì¸ í…Œì´ìŠ¤íŒ… ë…¸íŠ¸ì™€ ë§¤ë ¥ì ì¸ ì†Œê°œê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [ì‘ì„± ê·œì¹™]
    1. ì •ë³´ê°€ ë¶ˆí™•ì‹¤í•˜ë©´ ì¼ë°˜ì ì¸ í•´ë‹¹ ì¹´í…Œê³ ë¦¬/ì œí’ˆêµ°ì˜ íŠ¹ì§•ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ë„ˆë¬´ êµ¬ì²´ì ì¸ ê±°ì§“ ì •ë³´ëŠ” í”¼í•˜ì„¸ìš”.
    2. tasting_note: ë§›, í–¥, í”¼ë‹ˆì‹œë¥¼ ì¢…í•©í•œ 1~2ë¬¸ì¥ì˜ í•µì‹¬ ìš”ì•½. (í•œêµ­ì–´)
    3. description: ì‚¬ìš©ìì—ê²Œ ì´ ìˆ ì„ ì¶”ì²œí•˜ëŠ” ë§¤ë ¥ì ì¸ 2~3ë¬¸ì¥ì˜ ì†Œê°œê¸€. (í•œêµ­ì–´)
    4. ê²°ê³¼ëŠ” ì…ë ¥ëœ 'id'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë§¤í•‘í•  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

    [ì…ë ¥ ë°ì´í„°]
    {json.dumps(minimal_batch, ensure_ascii=False)}

    [ì¶œë ¥ í¬ë§· (JSON Array)]
    [
      {{
        "id": "item_id",
        "tasting_note": "ì‚°ëœ»í•œ ì‹œíŠ¸ëŸ¬ìŠ¤ í–¥ê³¼ ë°”ë‹ë¼ì˜ ë‹¬ì½¤í•¨ì´ ì–´ìš°ëŸ¬ì§„...",
        "description": "ì…ë¬¸ìë¶€í„° ì• í˜¸ê°€ê¹Œì§€ ëª¨ë‘ê°€ ì¦ê¸¸ ìˆ˜ ìˆëŠ”..."
      }}
    ]
    """

    for attempt in range(3):
        try:
            response = client.models.generate_content(
                model=MODEL_ID,
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            
            content = response.text.strip()
            # Remove potential markdown code blocks if present (though response_mime_type usually handles it)
            if content.startswith("```json"):
                content = content[7:]
            if content.endswith("```"):
                content = content[:-3]
            content = content.strip()

            enriched_results = json.loads(content)
            
            # Map results back to the original items
            mapping = {res['id']: res for res in enriched_results}
            
            updated_count = 0
            for item in batch:
                res = mapping.get(item['id'])
                if res:
                    if 'metadata' not in item:
                        item['metadata'] = {}
                    
                    # Update metadata with new info if valid
                    if res.get('tasting_note') and not item['metadata'].get('tasting_note'):
                        item['metadata']['tasting_note'] = res['tasting_note']
                    
                    if res.get('description') and not item['metadata'].get('description'):
                        item['metadata']['description'] = res['description']
                    
                    updated_count += 1
            
            return batch, updated_count

        except Exception as e:
            wait_time = (attempt + 1) * 5
            print(f"âš ï¸ API í˜¸ì¶œ ì‹¤íŒ¨ ({e}). {wait_time}ì´ˆ í›„ ì¬ì‹œë„...")
            time.sleep(wait_time)
            
    print("âŒ 3íšŒ ì¬ì‹œë„ ì‹¤íŒ¨. ì´ë²ˆ ë°°ì¹˜ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.")
    return batch, 0

def main():
    if not DATA_FILE.exists():
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DATA_FILE}")
        return

    print(f"ğŸš€ Gemini ë¦¬ë·° ë°ì´í„° ë³´ì™„ ì‹œì‘ (Target: {DATA_FILE})")
    
    # Load Data
    try:
        with open(DATA_FILE, 'r', encoding='utf-8') as f:
            all_spirits = json.load(f)
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    if not isinstance(all_spirits, list):
        print("âŒ ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ (Array expected).")
        return

    # Filter items that need enrichment (missing tasting_note or description)
    # We prioritize items that are already ingested/valid
    targets = []
    for s in all_spirits:
        meta = s.get('metadata', {})
        if not meta.get('tasting_note') or not meta.get('description'):
            targets.append(s)

    print(f"ğŸ“Š ì´ {len(all_spirits)}ê°œ í•­ëª© ì¤‘ ë³´ì™„ì´ í•„ìš”í•œ í•­ëª©: {len(targets)}ê°œ")

    if not targets:
        print("âœ¨ ëª¨ë“  í•­ëª©ì´ ì´ë¯¸ ë³´ì™„ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    # Backup functionality
    if not BACKUP_FILE.exists():
        with open(BACKUP_FILE, 'w', encoding='utf-8') as f:
            json.dump(all_spirits, f, indent=2, ensure_ascii=False)
        print("ğŸ’¾ ì›ë³¸ ë°ì´í„° ë°±ì—… ì™„ë£Œ.")

    BATCH_SIZE = 10
    total_processed = 0
    total_updated = 0

    try:
        # Process in batches
        for i in range(0, len(targets), BATCH_SIZE):
            batch = targets[i : i + BATCH_SIZE]
            print(f"ğŸ“¦ ì²˜ë¦¬ ì¤‘... ({i+1}/{len(targets)})")

            _, updated = enrich_reviews_batch(batch)
            total_updated += updated
            total_processed += len(batch)
            
            # Save progress periodically (files can be large, so maybe every 5 batches or just at end? 
            # Given it's a single JSON file database, rewriting it constantly is risky/slow. 
            # We will save every 50 items or at the end.)
            if total_processed % 50 == 0:
                print("ğŸ’¾ ì¤‘ê°„ ì €ì¥ ì¤‘...")
                with open(DATA_FILE, 'w', encoding='utf-8') as f:
                    json.dump(all_spirits, f, indent=2, ensure_ascii=False)
            
            time.sleep(1) # Gentle rate limiting

    except KeyboardInterrupt:
        print("\nğŸ›‘ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    finally:
        # Final Save
        print("ğŸ’¾ ìµœì¢… ë°ì´í„° ì €ì¥ ì¤‘...")
        with open(DATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(all_spirits, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ¨ ì‘ì—… ì™„ë£Œ!")
        print(f"- ì²˜ë¦¬ëœ í•­ëª©: {total_processed}")
        print(f"- ì—…ë°ì´íŠ¸ëœ ë‚´ìš©: {total_updated}ê±´")

if __name__ == "__main__":
    main()
